import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from datetime import datetime, timedelta
import sys
import os
import numpy as np
from plotly.subplots import make_subplots
import warnings
from prophet import Prophet


warnings.filterwarnings('ignore')

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
repo_root = os.path.abspath(os.path.join(current_dir, "..", "..", ".."))
sys.path.append(parent_dir)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞–∑—ã
try:
    from utils.data_loader import load_data_from_database, generate_server_data
    from utils.base_logger import logger
    from app.prophet_forecaster import ProphetForecaster
except ImportError as e:
    logger.info(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")


# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö
app_dir = os.path.join(parent_dir, '..', 'app')
sys.path.insert(0, app_dir)
try:
    from app.connection import SessionLocal
    from app.facts_crud import FactsCRUD
except ImportError:
    logger.info("–ú–æ–¥—É–ª–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ–∂–∏–º –¥–µ–º–æ")
    SessionLocal = None
    FactsCRUD = None


@st.cache_data(ttl=300)
def load_as_mapping_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –º–∞–ø–ø–∏–Ω–≥–µ —Å–µ—Ä–≤–µ—Ä–æ–≤ –Ω–∞ –ê–°"""
    try:
        file_path = os.path.join(repo_root, "data", "source", "all_vm.xlsx")
        if not os.path.exists(file_path):
            possible_paths = [
                os.path.join(repo_root, "data", "source", "all_vm.xlsx"),
                os.path.join("data", "source", "all_vm.xlsx"),
                "all_vm.xlsx",
            ]

            for path in possible_paths:
                if os.path.exists(path):
                    file_path = path
                    break

        if os.path.exists(file_path):
            df = pd.read_excel(file_path)
            mapping = {}
            for _, row in df.iterrows():
                server_name = str(row.get('–ò–º—è –ö–ï', '')).strip()
                as_name = str(row.get('–û–±—ä–µ–∫—Ç –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è (–ê–°/–ü–°)', '')).strip()

                if server_name and as_name and as_name != 'nan':
                    server_normalized = server_name.lower().replace('_', '-').replace(' ', '-')
                    mapping[server_normalized] = as_name
                    mapping[server_name] = as_name
            return mapping
    except Exception as e:
        st.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–∞–ø–ø–∏–Ω–≥–∞ –ê–°: {e}")
        servers = [f"Server_{i}" for i in range(1, 21)]
        as_list = ["ERP_System", "CRM_System", "HR_System", "Finance_System", "BI_System"]
        mapping = {}
        for server in servers:
            as_name = np.random.choice(as_list)
            mapping[server] = as_name
        return mapping


@st.cache_data(ttl=300)
def load_historical_data_for_as(as_name, as_mapping, history_days=30):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤ –ê–° —Å –æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å—é"""
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
        end_date = datetime.now()
        start_date = end_date - timedelta(days=history_days)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–µ—Ä–≤–µ—Ä–æ–≤ —ç—Ç–æ–π –ê–° (–≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–ø–∏—Å–∞–Ω–∏—è)
        servers_in_as = []
        for server, mapped_name in as_mapping.items():
            if str(mapped_name).strip() == str(as_name).strip():
                servers_in_as.append(server)
        
        st.info(f"–ù–∞–π–¥–µ–Ω–æ —Å–µ—Ä–≤–µ—Ä–æ–≤ –≤ –ê–° '{as_name}': {len(servers_in_as)}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–∏—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤
        if load_data_from_database:
            try:
                data = load_data_from_database(start_date=start_date, end_date=end_date)
                st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π –∏–∑ –ë–î")
            except Exception as db_error:
                st.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ –ë–î: {db_error}")
                
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Å–µ—Ä–≤–µ—Ä–∞–º —ç—Ç–æ–π –ê–°
        if 'server' in data.columns and 'as_name' not in data.columns:
            data['as_name'] = data['server'].map(as_mapping)
        
        if 'as_name' in data.columns:
            filtered_data = data[data['as_name'] == as_name]
            st.success(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(filtered_data)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –ê–° '{as_name}'")
        else:
            filtered_data = data
            st.warning("–ö–æ–ª–æ–Ω–∫–∞ as_name –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É—é –≤—Å–µ –¥–∞–Ω–Ω—ã–µ")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –º–µ—Ç—Ä–∏–∫
        required_metrics = ['cpu.usage.average', 'mem.usage.average']
        available_metrics = [col for col in filtered_data.columns if any(m in col for m in ['cpu', 'mem', 'usage'])]
        
        if not available_metrics:
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ–º–æ-–º–µ—Ç—Ä–∏–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
            for metric in required_metrics:
                filtered_data[metric] = np.random.uniform(10, 80, len(filtered_data))
        
        return filtered_data
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ê–° {as_name}: {e}")
        import traceback
        st.code(traceback.format_exc())


def prepare_data_for_prophet(df, metric, server_name=None):
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è Prophet —Å –º–µ–Ω–µ–µ —Å—Ç—Ä–æ–≥–∏–º–∏ —É—Å–ª–æ–≤–∏—è–º–∏"""
    if df.empty:
        return pd.DataFrame()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö
    available_columns = df.columns.tolist()
    if metric not in available_columns:
        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        similar_metrics = [col for col in available_columns if metric.split('.')[0] in col.lower()]
        if similar_metrics:
            metric = similar_metrics[0]
        else:
            return pd.DataFrame()
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
    if server_name:
        df_filtered = df[df['server'] == server_name].copy()
    else:
        df_filtered = df.copy()
    
    if df_filtered.empty:
        return pd.DataFrame()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ timestamp
    if 'timestamp' not in df_filtered.columns:
        # –ò—â–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
        time_cols = [col for col in df_filtered.columns if 'time' in col.lower() or 'date' in col.lower()]
        if time_cols:
            df_filtered = df_filtered.rename(columns={time_cols[0]: 'timestamp'})
        else:
            return pd.DataFrame()
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Prophet
    try:
        prophet_df = df_filtered[['timestamp', metric]].copy()
        prophet_df.columns = ['ds', 'y']
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ datetime
        prophet_df['ds'] = pd.to_datetime(prophet_df['ds'], errors='coerce')
        prophet_df = prophet_df.dropna(subset=['ds', 'y'])
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        prophet_df = prophet_df.drop_duplicates(subset=['ds'])
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ - 4 —Ç–æ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        if len(prophet_df) < 4:
            st.warning(f"–î–ª—è —Å–µ—Ä–≤–µ—Ä–∞ {server_name} –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(prophet_df)} —Ç–æ—á–µ–∫")
            return pd.DataFrame()
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        prophet_df['ds'] = pd.to_datetime(prophet_df['ds']).dt.tz_localize(None)
        prophet_df = prophet_df.sort_values('ds')
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö
        st.info(f"–î–∞–Ω–Ω—ã–µ –¥–ª—è {server_name}: {len(prophet_df)} —Ç–æ—á–µ–∫ —Å {prophet_df['ds'].min()} –ø–æ {prophet_df['ds'].max()}")
        
        return prophet_df
        
    except Exception as e:
        st.warning(f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {server_name}: {str(e)}")
        return pd.DataFrame()


def generate_forecast_for_server(prophet_df: pd.DataFrame, forecast_days: int):
    def add_time_features(df: pd.DataFrame) -> pd.DataFrame:
        df = df.copy()
        dt = df['ds']
        df['hour'] = dt.dt.hour
        df['day_of_week'] = dt.dt.dayofweek
        df['day_of_month'] = dt.dt.day
        df['week_of_year'] = dt.dt.isocalendar().week.astype(int)
        df['month'] = dt.dt.month
        df['quarter'] = dt.dt.quarter
        df['is_weekend'] = (dt.dt.dayofweek >= 5).astype(int)
        df['is_month_start'] = dt.dt.is_month_start.astype(int)
        df['is_month_end'] = dt.dt.is_month_end.astype(int)
        df['is_quarter_start'] = dt.dt.is_quarter_start.astype(int)
        df['is_quarter_end'] = dt.dt.is_quarter_end.astype(int)
        df['is_year_start'] = dt.dt.is_year_start.astype(int)
        df['is_year_end'] = dt.dt.is_year_end.astype(int)
        return df

    def build_model(params: dict, feature_columns: list) -> Prophet:
        model = Prophet(
            daily_seasonality=params['daily_seasonality'],
            weekly_seasonality=params['weekly_seasonality'],
            yearly_seasonality=params['yearly_seasonality'],
            seasonality_mode=params['seasonality_mode'],
            changepoint_prior_scale=params['changepoint_prior_scale'],
            seasonality_prior_scale=params['seasonality_prior_scale'],
            holidays_prior_scale=params['holidays_prior_scale'],
            changepoint_range=params['changepoint_range'],
            n_changepoints=params['n_changepoints'],
        )
        for col in feature_columns:
            model.add_regressor(col)
        return model

    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    prophet_df = add_time_features(prophet_df)
    feature_columns = [
        'hour',
        'day_of_week',
        'day_of_month',
        'week_of_year',
        'month',
        'quarter',
        'is_weekend',
        'is_month_start',
        'is_month_end',
        'is_quarter_start',
        'is_quarter_end',
        'is_year_start',
        'is_year_end',
    ]

    def evaluate_with_holdout(train_data: pd.DataFrame, val_data: pd.DataFrame, params: dict) -> float:
        model = build_model(params, feature_columns)
        model.fit(train_data)
        val_forecast = model.predict(val_data[['ds'] + feature_columns])
        val_actual = val_data['y'].values
        val_pred = val_forecast['yhat'].values
        return float(np.mean(np.abs(val_actual - val_pred)))

    def evaluate_with_cv(data: pd.DataFrame, params: dict, n_splits: int, horizon_points: int) -> float:
        maes = []
        total_points = len(data)
        for split_idx in range(1, n_splits + 1):
            train_end = total_points - horizon_points * (n_splits - split_idx + 1)
            train_df = data.iloc[:train_end]
            val_df = data.iloc[train_end:train_end + horizon_points]
            if len(train_df) < 4 or len(val_df) < 4:
                continue
            try:
                mae = evaluate_with_holdout(train_df, val_df, params)
                maes.append(mae)
            except Exception:
                continue
        if not maes:
            return np.inf
        return float(np.mean(maes))

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ train/val —Ä–∞–∑–±–∏–µ–Ω–∏—è –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    prophet_df = prophet_df.sort_values('ds')
    total_points = len(prophet_df)
    yearly_seasonality = (prophet_df['ds'].max() - prophet_df['ds'].min()).days >= 365

    if total_points < 8:
        fallback_params = {
            'daily_seasonality': True,
            'weekly_seasonality': True,
            'yearly_seasonality': yearly_seasonality,
            'seasonality_mode': 'additive',
            'changepoint_prior_scale': 0.05,
            'seasonality_prior_scale': 10.0,
            'holidays_prior_scale': 10.0,
            'changepoint_range': 0.9,
            'n_changepoints': 25,
        }
        best_model = build_model(fallback_params, feature_columns)
        best_model.fit(prophet_df)

        forecast_hours = forecast_days * 24
        future = best_model.make_future_dataframe(
            periods=forecast_hours * 2,
            freq='30min',
            include_history=False
        )
        future = add_time_features(future)
        forecast = best_model.predict(future[['ds'] + feature_columns])
        return forecast, best_model, None, "default"

    val_size = max(10, int(total_points * 0.2))
    val_size = min(val_size, total_points - 4)

    train_df = prophet_df.iloc[:-val_size].copy()
    val_df = prophet_df.iloc[-val_size:].copy()

    # –°–µ—Ç–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    param_grid = [
        {
            'daily_seasonality': True,
            'weekly_seasonality': True,
            'yearly_seasonality': yearly_seasonality,
            'seasonality_mode': seasonality_mode,
            'changepoint_prior_scale': cps,
            'seasonality_prior_scale': sps,
            'holidays_prior_scale': hps,
            'changepoint_range': cpr,
            'n_changepoints': ncp,
        }
        for seasonality_mode in ['additive', 'multiplicative']
        for cps in [0.01, 0.05, 0.1, 0.2]
        for sps in [3.0, 5.0, 10.0, 15.0]
        for hps in [5.0, 10.0]
        for cpr in [0.8, 0.9, 0.95]
        for ncp in [15, 25, 35]
    ]

    # –ü–æ–¥–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –ø–æ MAE –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏–ª–∏ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
    best_score = np.inf
    best_params = None
    best_model = None

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–æ–≥–¥–∞ —É–º–µ—Å—Ç–Ω–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
    horizon_points = max(8, min(48, int(total_points * 0.1)))
    max_splits = total_points // (horizon_points * 2)
    n_splits = min(4, max(2, max_splits))
    use_cv = n_splits >= 2 and total_points >= (horizon_points * (n_splits + 1))
    eval_method = "cv" if use_cv else "holdout"

    for params in param_grid:
        try:
            if use_cv:
                mae = evaluate_with_cv(prophet_df, params, n_splits, horizon_points)
            else:
                mae = evaluate_with_holdout(train_df, val_df, params)

            if mae < best_score:
                best_score = mae
                best_params = params
        except Exception:
            continue

    # –ï—Å–ª–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    if best_params is None:
        fallback_params = {
            'daily_seasonality': True,
            'weekly_seasonality': True,
            'yearly_seasonality': yearly_seasonality,
            'seasonality_mode': 'additive',
            'changepoint_prior_scale': 0.05,
            'seasonality_prior_scale': 10.0,
            'holidays_prior_scale': 10.0,
            'changepoint_range': 0.9,
            'n_changepoints': 25,
        }
        best_model = build_model(fallback_params, feature_columns)
        best_model.fit(prophet_df)
    else:
        # –ü–µ—Ä–µ–æ–±—É—á–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
        best_model = build_model(best_params, feature_columns)
        best_model.fit(prophet_df)

    # –°–æ–∑–¥–∞–µ–º —Ñ—Ä–µ–π–º –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
    forecast_hours = forecast_days * 24
    future = best_model.make_future_dataframe(
        periods=forecast_hours * 2,
        freq='30min',
        include_history=False
    )
    future = add_time_features(future)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≥–Ω–æ–∑
    forecast = best_model.predict(future[['ds'] + feature_columns])
    return forecast, best_model, best_score, eval_method


def generate_forecast_for_as(as_name, servers_data, metric, forecast_days, as_mapping):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –≤—Å–µ—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤ –ê–°"""
    results = {}

    for server in servers_data['server'].unique():
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
        prophet_df = prepare_data_for_prophet(servers_data, metric, server)

        if prophet_df.empty:
            continue

        try:
            forecast, model, quality_mae, quality_method = generate_forecast_for_server(
                prophet_df,
                forecast_days
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results[server] = {
                'forecast': forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']],
                'model': model,
                'history': prophet_df,
                'quality_mae': quality_mae,
                'quality_method': quality_method
            }

        except Exception as e:
            st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è —Å–µ—Ä–≤–µ—Ä–∞ {server}: {e}")
            continue

    return results


def create_forecast_plot(server_name, forecast_results, metric, as_name):
    """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞"""
    if server_name not in forecast_results:
        return None

    result = forecast_results[server_name]
    forecast_df = result['forecast']
    history_df = result['history']

    fig = go.Figure()

    # –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    if not history_df.empty:
        fig.add_trace(go.Scatter(
            x=history_df['ds'],
            y=history_df['y'],
            mode='lines',
            name='–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ',
            line=dict(color='#1E88E5', width=2),
            hovertemplate='<b>%{x}</b><br>–ó–Ω–∞—á–µ–Ω–∏–µ: %{y:.1f}%<extra></extra>'
        ))

    # –ü—Ä–æ–≥–Ω–æ–∑
    fig.add_trace(go.Scatter(
        x=forecast_df['ds'],
        y=forecast_df['yhat'],
        mode='lines',
        name='–ü—Ä–æ–≥–Ω–æ–∑',
        line=dict(color='#FF5722', width=3, dash='dash'),
        hovertemplate='<b>%{x}</b><br>–ü—Ä–æ–≥–Ω–æ–∑: %{y:.1f}%<extra></extra>'
    ))

    # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
    fig.add_trace(go.Scatter(
        x=forecast_df['ds'].tolist() + forecast_df['ds'].tolist()[::-1],
        y=forecast_df['yhat_upper'].tolist() + forecast_df['yhat_lower'].tolist()[::-1],
        fill='toself',
        fillcolor='rgba(255, 87, 34, 0.2)',
        line=dict(color='rgba(255,255,255,0)'),
        hoverinfo='skip',
        name='–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª (80%)'
    ))

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ layout
    metric_name = "CPU" if "cpu" in metric.lower() else "RAM"
    fig.update_layout(
        title=f'<b>{server_name}</b><br>–ü—Ä–æ–≥–Ω–æ–∑ {metric_name} –Ω–∞–≥—Ä—É–∑–∫–∏',
        xaxis_title='<b>–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è</b>',
        yaxis_title=f'<b>–ù–∞–≥—Ä—É–∑–∫–∞ {metric_name} (%)</b>',
        height=400,
        hovermode='x unified',
        plot_bgcolor='rgba(240, 242, 246, 1)',
        paper_bgcolor='rgba(255, 255, 255, 1)',
        legend=dict(
            yanchor="top",
            y=0.99,
            xanchor="left",
            x=0.01,
            bgcolor='rgba(255, 255, 255, 0.9)'
        ),
        margin=dict(l=50, r=30, t=80, b=50)
    )

    return fig


def create_summary_table(forecast_results, as_name, metric):
    """–°–æ–∑–¥–∞–µ—Ç —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –ø—Ä–æ–≥–Ω–æ–∑–æ–≤"""
    summary_data = []

    for server, result in forecast_results.items():
        forecast_df = result['forecast']

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        avg_forecast = forecast_df['yhat'].mean()
        max_forecast = forecast_df['yhat'].max()
        min_forecast = forecast_df['yhat'].min()

        # –í—Ä–µ–º—è –ø–∏–∫–æ–≤–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏
        max_idx = forecast_df['yhat'].idxmax()
        peak_time = forecast_df.loc[max_idx, 'ds']

        # –û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞
        if max_forecast > 85:
            risk_level = "üü• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π"
        elif max_forecast > 70:
            risk_level = "üüß –í—ã—Å–æ–∫–∏–π"
        elif max_forecast > 50:
            risk_level = "üü® –°—Ä–µ–¥–Ω–∏–π"
        else:
            risk_level = "üü© –ù–∏–∑–∫–∏–π"

        quality_mae = result.get('quality_mae')
        quality_method = result.get('quality_method', 'unknown')
        quality_label = "‚Äî" if quality_mae is None else f"{quality_mae:.3f}"

        summary_data.append({
            '–°–µ—Ä–≤–µ—Ä': server,
            '–°—Ä–µ–¥–Ω—è—è': f"{avg_forecast:.1f}%",
            '–ú–∞–∫—Å–∏–º—É–º': f"{max_forecast:.1f}%",
            '–ú–∏–Ω–∏–º—É–º': f"{min_forecast:.1f}%",
            '–ü–∏–∫ –≤': peak_time.strftime('%d.%m %H:%M'),
            '–†–∏—Å–∫': risk_level,
            'MAE': quality_label,
            '–ú–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏': quality_method
        })

    return pd.DataFrame(summary_data)


def show():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ –ê–°"""
    st.markdown('<h2 class="sub-header">üîÆ –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞–≥—Ä—É–∑–∫–∏ –ø–æ –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –°–∏—Å—Ç–µ–º–∞–º</h2>', unsafe_allow_html=True)

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –ê–°
        with st.spinner("–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ–± –ê–°..."):
            as_mapping = load_as_mapping_data()

        if not as_mapping:
            st.error("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ–± –ê–°")
            return

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ê–°
        all_as = sorted(set(as_mapping.values()))

        if not all_as:
            st.warning("‚ö†Ô∏è –ê–° –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
            return

        col1, col2 = st.columns([1, 3])

        with col1:
            st.markdown('<div class="server-selector fade-in">', unsafe_allow_html=True)

            # –í—ã–±–æ—Ä –ê–°
            selected_as = st.selectbox(
                "**–í—ã–±–µ—Ä–∏—Ç–µ –ê–° –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞:**",
                all_as,
                index=0 if all_as else None,
                key="forecast_as_select"
            )

            # –í—ã–±–æ—Ä –º–µ—Ç—Ä–∏–∫–∏
            metric_options = {
                "cpu.usage.average": "cpu.usage.average",
                "mem.usage.average": "mem.usage.average"
            }

            selected_metric = st.selectbox(
                "**–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç—Ä–∏–∫—É:**",
                list(metric_options.keys()),
                format_func=lambda x: metric_options[x],
                key="forecast_metric_select"
            )

            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ–≥–Ω–æ–∑–∞
            st.markdown("### ‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã")

            forecast_days = st.slider(
                "**–ü–µ—Ä–∏–æ–¥ –ø—Ä–æ–≥–Ω–æ–∑–∞ (–¥–Ω–µ–π):**",
                min_value=1,
                max_value=14,
                value=7,
                step=1,
                key="forecast_days"
            )

            history_days = st.slider(
                "**–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (–¥–Ω–µ–π):**",
                min_value=7,
                max_value=90,
                value=30,
                step=7,
                key="history_days"
            )

            # –û–ø—Ü–∏–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            st.markdown("### üëÅÔ∏è –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ")

            show_individual = st.checkbox(
                "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏",
                value=True,
                help="–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞"
            )

            max_servers_to_show = st.slider(
                "–ú–∞–∫—Å–∏–º—É–º —Å–µ—Ä–≤–µ—Ä–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è:",
                min_value=5,
                max_value=20,
                value=10,
                step=1
            )

            # –ö–Ω–æ–ø–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞
            generate_btn = st.button(
                "üöÄ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑",
                type="primary",
                use_container_width=True,
                key="generate_forecast_btn"
            )

            st.markdown('</div>', unsafe_allow_html=True)

        with col2:
            if generate_btn or st.session_state.get('forecast_generated', False):
                st.session_state.forecast_generated = True

                with st.spinner(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ê–° '{selected_as}'..."):
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ê–°
                    servers_data = load_historical_data_for_as(
                        selected_as,
                        as_mapping,
                        history_days
                    )

                if servers_data.empty:
                    st.warning(f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ê–° '{selected_as}'")
                    return

                # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–µ—Ä–≤–µ—Ä–æ–≤ –≤ —ç—Ç–æ–π –ê–°
                servers_in_as = servers_data['server'].unique().tolist()
                server_count = len(servers_in_as)

                st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {server_count} —Å–µ—Ä–≤–µ—Ä–æ–≤ –≤ –ê–° '{selected_as}'")

                # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞
                progress_bar = st.progress(0)
                status_text = st.empty()

                with st.spinner("–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≥–Ω–æ–∑—ã..."):
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≥–Ω–æ–∑—ã –¥–ª—è –≤—Å–µ—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤
                    forecast_results = generate_forecast_for_as(
                        selected_as,
                        servers_data,
                        selected_metric,
                        forecast_days,
                        as_mapping
                    )

                if not forecast_results:
                    st.error("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑—ã")
                    return

                # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                st.markdown("### üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞")

                col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)

                with col_stat1:
                    st.metric("–ê–°", selected_as)

                with col_stat2:
                    st.metric("–°–µ—Ä–≤–µ—Ä–æ–≤", f"{len(forecast_results)}/{server_count}")

                with col_stat3:
                    # –°—Ä–µ–¥–Ω—è—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞
                    max_loads = []
                    for result in forecast_results.values():
                        max_loads.append(result['forecast']['yhat'].max())
                    avg_max_load = np.mean(max_loads) if max_loads else 0
                    st.metric("–°—Ä. –ø–∏–∫ –Ω–∞–≥—Ä—É–∑–∫–∏", f"{avg_max_load:.1f}%")

                with col_stat4:
                    # –°–µ—Ä–≤–µ—Ä—ã —Å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –Ω–∞–≥—Ä—É–∑–∫–æ–π
                    critical_servers = 0
                    for result in forecast_results.values():
                        if result['forecast']['yhat'].max() > 85:
                            critical_servers += 1
                    st.metric("–ö—Ä–∏—Ç–∏—á. —Å–µ—Ä–≤–µ—Ä–æ–≤", critical_servers)

                # –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
                st.markdown("### üìã –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤")
                summary_df = create_summary_table(forecast_results, selected_as, selected_metric)

                # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Ä–∏—Å–∫—É –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –Ω–∞–≥—Ä—É–∑–∫–µ
                def risk_sort_key(row):
                    risk_map = {"üü• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π": 0, "üüß –í—ã—Å–æ–∫–∏–π": 1, "üü® –°—Ä–µ–¥–Ω–∏–π": 2, "üü© –ù–∏–∑–∫–∏–π": 3}
                    return risk_map.get(row['–†–∏—Å–∫'], 4)

                summary_df['risk_numeric'] = summary_df.apply(risk_sort_key, axis=1)
                summary_df = summary_df.sort_values(['risk_numeric', '–ú–∞–∫—Å–∏–º—É–º'], ascending=[True, False])
                summary_df = summary_df.drop('risk_numeric', axis=1)

                # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å —Ü–≤–µ—Ç–æ–≤—ã–º –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
                st.dataframe(
                    summary_df.style.apply(
                        lambda x: ['background-color: #ffcccc' if '–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π' in str(v) else
                                   'background-color: #ffe6cc' if '–í—ã—Å–æ–∫–∏–π' in str(v) else
                                   'background-color: #fff2cc' if '–°—Ä–µ–¥–Ω–∏–π' in str(v) else
                                   'background-color: #d9ead3' for v in x],
                        subset=['–†–∏—Å–∫']
                    ),
                    use_container_width=True,
                    height=400
                )

                # –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏
                if show_individual and forecast_results:
                    st.markdown("### üìà –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≥–Ω–æ–∑—ã")

                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤
                    servers_to_show = list(forecast_results.keys())[:max_servers_to_show]

                    for i, server in enumerate(servers_to_show):
                        st.markdown(f"#### –°–µ—Ä–≤–µ—Ä: {server}")

                        fig = create_forecast_plot(
                            server,
                            forecast_results,
                            selected_metric,
                            selected_as
                        )

                        if fig:
                            st.plotly_chart(fig, use_container_width=True)

                        # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –º–µ–∂–¥—É —Å–µ—Ä–≤–µ—Ä–∞–º–∏
                        if i < len(servers_to_show) - 1:
                            st.divider()

                # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –ø–æ –ê–°
                st.markdown("### üìä –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –ø–æ –ê–°")

                try:
                    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–æ–≥–Ω–æ–∑—ã –≤ –æ–¥–∏–Ω DataFrame
                    all_forecasts = []
                    for server, result in forecast_results.items():
                        forecast_df = result['forecast'].copy()
                        forecast_df['server'] = server
                        all_forecasts.append(forecast_df)

                    if all_forecasts:
                        combined_forecasts = pd.concat(all_forecasts, ignore_index=True)

                        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                        aggregated = combined_forecasts.groupby('ds').agg({
                            'yhat': 'mean',
                            'yhat_lower': 'mean',
                            'yhat_upper': 'mean'
                        }).reset_index()

                        # –°–æ–∑–¥–∞–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫
                        fig_agg = go.Figure()

                        fig_agg.add_trace(go.Scatter(
                            x=aggregated['ds'],
                            y=aggregated['yhat'],
                            mode='lines',
                            name='–°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ–≥–Ω–æ–∑',
                            line=dict(color='#4CAF50', width=3),
                            hovertemplate='<b>%{x}</b><br>–°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä—É–∑–∫–∞: %{y:.1f}%<extra></extra>'
                        ))

                        fig_agg.add_trace(go.Scatter(
                            x=aggregated['ds'].tolist() + aggregated['ds'].tolist()[::-1],
                            y=aggregated['yhat_upper'].tolist() + aggregated['yhat_lower'].tolist()[::-1],
                            fill='toself',
                            fillcolor='rgba(76, 175, 80, 0.2)',
                            line=dict(color='rgba(255,255,255,0)'),
                            hoverinfo='skip',
                            name='–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª'
                        ))

                        metric_name = "CPU" if "cpu" in selected_metric.lower() else "RAM"
                        fig_agg.update_layout(
                            title=f'<b>–ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ {metric_name} –Ω–∞–≥—Ä—É–∑–∫–∏ –¥–ª—è –ê–° "{selected_as}"</b>',
                            xaxis_title='<b>–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è</b>',
                            yaxis_title=f'<b>–°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä—É–∑–∫–∞ {metric_name} (%)</b>',
                            height=500,
                            hovermode='x unified',
                            plot_bgcolor='rgba(240, 242, 246, 1)',
                            paper_bgcolor='rgba(255, 255, 255, 1)'
                        )

                        st.plotly_chart(fig_agg, use_container_width=True)

                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –ø—Ä–æ–≥–Ω–æ–∑—É
                        col_agg1, col_agg2, col_agg3 = st.columns(3)
                        with col_agg1:
                            avg_load = aggregated['yhat'].mean()
                            st.metric("–°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä—É–∑–∫–∞", f"{avg_load:.1f}%")

                        with col_agg2:
                            peak_load = aggregated['yhat'].max()
                            peak_time = aggregated.loc[aggregated['yhat'].idxmax(), 'ds']
                            st.metric("–ü–∏–∫–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞", f"{peak_load:.1f}%", f"–≤ {peak_time.strftime('%H:%M')}")

                        with col_agg3:
                            if peak_load > 85:
                                overall_risk = "üü• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π"
                            elif peak_load > 65:
                                overall_risk = "üüß –í—ã—Å–æ–∫–∏–π"
                            elif peak_load > 50:
                                overall_risk = "üü® –°—Ä–µ–¥–Ω–∏–π"
                            else:
                                overall_risk = "üü© –ù–∏–∑–∫–∏–π"
                            st.metric("–û–±—â–∏–π —Ä–∏—Å–∫", overall_risk)

                except Exception as e:
                    st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑: {e}")

                # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                st.markdown("### üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ê–°")

                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∏—Å–∫–∏
                critical_count = 0
                high_count = 0
                for result in forecast_results.values():
                    max_load = result['forecast']['yhat'].max()
                    if max_load > 85:
                        critical_count += 1
                    elif max_load > 70:
                        high_count += 1

                if critical_count > 0:
                    st.error(f"""
                    **‚ö†Ô∏è –¢—Ä–µ–±—É—é—Ç—Å—è —Å—Ä–æ—á–Ω—ã–µ –º–µ—Ä—ã ({critical_count} —Å–µ—Ä–≤–µ—Ä–æ–≤ —Å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –Ω–∞–≥—Ä—É–∑–∫–æ–π):**
                    - **–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤:** –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ CPU/RAM –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤
                    - **–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –Ω–∞–≥—Ä—É–∑–∫–∏:** –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤—å—Ç–µ —á–∞—Å—Ç—å –Ω–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ –º–µ–Ω–µ–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Å–µ—Ä–≤–µ—Ä—ã
                    - **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π:** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –∫–æ–¥–∞ –∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –ë–î
                    - **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏:** –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∞–ª–µ—Ä—Ç—ã –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ—Ä–æ–≥–æ–≤
                    """)
                elif high_count > 0:
                    st.warning(f"""
                    **üü° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ ({high_count} —Å–µ—Ä–≤–µ—Ä–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π –Ω–∞–≥—Ä—É–∑–∫–æ–π):**
                    - **–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤:** –ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –ø–ª–∞–Ω –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –ø–∏–∫–æ–≤—ã–µ –ø–µ—Ä–∏–æ–¥—ã
                    - **–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤:** –ò–∑—É—á–∏—Ç–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞–≥—Ä—É–∑–∫–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                    - **–†–µ–∑–µ—Ä–≤–Ω—ã–µ –º–æ—â–Ω–æ—Å—Ç–∏:** –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –Ω–∞–ª–∏—á–∏–∏ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤
                    - **–ü—Ä–æ–∞–∫—Ç–∏–≤–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:** –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∞–ª–µ—Ä—Ç—ã –Ω–∞ 70% –Ω–∞–≥—Ä—É–∑–∫—É
                    """)
                else:
                    st.success(f"""
                    **üü¢ –°–∏—Å—Ç–µ–º–∞ —Å—Ç–∞–±–∏–ª—å–Ω–∞:**
                    - **–¢–µ–∫—É—â–∏–µ —Ä–µ—Å—É—Ä—Å—ã –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã:** –í—Å–µ —Å–µ—Ä–≤–µ—Ä—ã –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –Ω–æ—Ä–º—ã
                    - **–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:** –†–µ–≥—É–ª—è—Ä–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –º–µ—Ç—Ä–∏–∫–∏
                    - **–ü–ª–∞–Ω–æ–≤–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ:** –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π
                    - **–ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏:** –ò–∑—É—á–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞—Ç—Ä–∞—Ç
                    """)

                # –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö
                st.markdown("---")
                col_export1, col_export2 = st.columns(2)

                with col_export1:
                    if st.button("üìä –≠–∫—Å–ø–æ—Ä—Ç –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ (CSV)", type="secondary", use_container_width=True):
                        try:
                            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
                            export_data = []
                            for server, result in forecast_results.items():
                                forecast_df = result['forecast'].copy()
                                forecast_df['server'] = server
                                forecast_df['as_name'] = selected_as
                                forecast_df['metric'] = selected_metric
                                export_data.append(forecast_df)

                            if export_data:
                                export_df = pd.concat(export_data, ignore_index=True)
                                csv = export_df.to_csv(index=False, encoding='utf-8-sig')

                                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                filename = f"forecast_{selected_as}_{selected_metric}_{timestamp}.csv"

                                st.download_button(
                                    label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å CSV",
                                    data=csv,
                                    file_name=filename,
                                    mime="text/csv",
                                    use_container_width=True
                                )
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}")

                with col_export2:
                    if st.button("üìà –≠–∫—Å–ø–æ—Ä—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞", type="secondary", use_container_width=True):
                        st.info("–§—É–Ω–∫—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –≥—Ä–∞—Ñ–∏–∫–∞ –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ")

            else:
                # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞—Ö–æ–¥–µ
                st.markdown('<div class="info-card">', unsafe_allow_html=True)

                st.markdown("## üëã –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –º–æ–¥—É–ª—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ –ê–°!")

                st.info("""
                **üìã –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –º–æ–¥—É–ª—è:**
                - –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞–≥—Ä—É–∑–∫–∏ CPU –∏ RAM –¥–ª—è –≤—Å–µ—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ê–°
                - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Prophet –¥–ª—è —Ç–æ—á–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
                - –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Å–µ–π –ê–°
                - –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
                - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—é —Ä–µ—Å—É—Ä—Å–æ–≤
                """)

                col_info1, col_info2 = st.columns(2)

                with col_info1:
                    st.markdown("""
                    **üöÄ –î–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã:**
                    1. –í—ã–±–µ—Ä–∏—Ç–µ –ê–° –∏–∑ —Å–ø–∏—Å–∫–∞ —Å–ª–µ–≤–∞
                    2. –í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç—Ä–∏–∫—É (CPU –∏–ª–∏ RAM)
                    3. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–µ—Ä–∏–æ–¥ –ø—Ä–æ–≥–Ω–æ–∑–∞
                    4. –ù–∞–∂–º–∏—Ç–µ "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑"
                    """)

                with col_info2:
                    st.markdown("""
                    **üìä –í—ã –ø–æ–ª—É—á–∏—Ç–µ:**
                    - –°–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —Å –ø—Ä–æ–≥–Ω–æ–∑–∞–º–∏
                    - –ì—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
                    - –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –ø–æ –ê–°
                    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                    - –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö
                    """)

                st.divider()

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–æ—Å—Ç—É–ø–Ω—ã–º –ê–°
                st.markdown("### üìà –î–æ—Å—Ç—É–ø–Ω—ã–µ –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –°–∏—Å—Ç–µ–º—ã")

                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–µ—Ä–≤–µ—Ä—ã –≤ –∫–∞–∂–¥–æ–π –ê–°
                as_stats = {}
                for server, as_name in as_mapping.items():
                    if as_name not in as_stats:
                        as_stats[as_name] = 0
                    as_stats[as_name] += 1

                # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                stats_df = pd.DataFrame([
                    {'–ê–°': as_name, '–ö–æ–ª-–≤–æ —Å–µ—Ä–≤–µ—Ä–æ–≤': count}
                    for as_name, count in as_stats.items()
                ]).sort_values('–ö–æ–ª-–≤–æ —Å–µ—Ä–≤–µ—Ä–æ–≤', ascending=False)

                # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
                st.dataframe(
                    stats_df.style.background_gradient(
                        subset=['–ö–æ–ª-–≤–æ —Å–µ—Ä–≤–µ—Ä–æ–≤'],
                        cmap='Blues'
                    ),
                    use_container_width=True,
                    height=300
                )

                st.markdown('</div>', unsafe_allow_html=True)

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        import traceback
        with st.expander("–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏"):
            st.code(traceback.format_exc())

